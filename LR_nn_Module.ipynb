{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LR_nn_Module.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOq70BeId43hwxwa6uokH83",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prgmr99/deep_learning-pytorch-/blob/main/LR_nn_Module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **nn.Module로 구현하는 선형 회귀**\n",
        "\n",
        "이전까지는 선형 회귀를 좀 더 직접적으로 이해하기 위해 가설, 비용 함수를 직접 정의해서 선형 회귀 모델을 구현했다.\n",
        "\n",
        "이번에는 파이토치에서 이미 구현되어져 제공되고 있는 함수들을 불러오는 것으로 더 쉽게 선형 회귀 모델을 구현해보겠다.\n"
      ],
      "metadata": {
        "id": "7prsM9CpKeDs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_9QICmmeKBAa"
      },
      "outputs": [],
      "source": [
        "# 파이토치에서는 선형 회귀 모델이 nn.Linear()라는 함수로,\n",
        "# 평균 제곱오차가 nn.function.mse_loss()라는 함수로 구현되어져 있다.\n",
        "\n",
        "# 사용 예제\n",
        "import torch.nn as nn\n",
        "#model=nn.Linear(input_dim, output_dim) # 에러 떠서 주석처리\n",
        "\n",
        "import torch.nn.functional as F\n",
        "#cost=F.mse_loss(prediction, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **단순 선형 회귀 구현하기**"
      ],
      "metadata": {
        "id": "m2tlfnDqMAVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 도구 임포트\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jB31Sn04LgIt",
        "outputId": "6cc1f1bb-0fab-47d8-f540-fe8d8a32f9df"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f5855547dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 선언(y=2*x를 가정한 상태에서 데이터 만듬)\n",
        "# w=2, b=0임을 알고 있기 때문에 w,b 값을 제대로 찾아내도록 하는 것이 목표.\n",
        "x_train=torch.FloatTensor(([1],[2],[3]))\n",
        "y_train=torch.FloatTensor(([2],[4],[6]))"
      ],
      "metadata": {
        "id": "52p_VOVxMS-L"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 선형 회귀 모델 구현\n",
        "# nn.Linear()는 입력의 차원, 출력의 차원을 인수로 받는다.\n",
        "\n",
        "# 모델을 선언/초기화. 단순 선형 회귀이므로 input_dim=1, output_dim=1\n",
        "model=nn.Linear(1,1)\n",
        "\n",
        "# 입력 차원과 출력 차원 모두 1을 인수로 사용.\n",
        "# model에는 가중치 w와 편향 b가 저장되어져 있다.\n",
        "# 이 값들은 model.parameters()라는 함수를 사용해 불러올 수 있다.\n",
        "print(list(model.parameters()))\n",
        "\n",
        "# 두 값 모두 현재는 랜덤 초기화가 되어져 있다. \n",
        "# 두 값 모두 학습의 대상이므로 requires_grad=True가 되어져 있다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAUqf6jnM0o7",
        "outputId": "34a7756a-ffa6-4bf8-ed91-4756be847cff"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[-0.1939]], requires_grad=True), Parameter containing:\n",
            "tensor([0.4694], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 옵티마이저 정의\n",
        "# model.parameters()를 사용하여 w와 b를 전달\n",
        "\n",
        "# optimizer 설정. 경사 하강법 SGD 사용, lr=0.01\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=0.01)"
      ],
      "metadata": {
        "id": "w52773r1OsKx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epochs=2000\n",
        "for epoch in range(nb_epochs+1):\n",
        "\n",
        "  # H(x) 계산\n",
        "  prediction=model(x_train)\n",
        "\n",
        "  # cost 계산\n",
        "  cost=F.mse_loss(prediction,y_train) # 파이토치에서 제공하는 평균 제곱 오차 함수\n",
        "\n",
        "  # cost로 H(x) 개선하는 부분\n",
        "  # gradient를 0으로 초기화\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # 비용 함수를 미분하여 gradient 계산\n",
        "  cost.backward()\n",
        "\n",
        "  # W와 b를 업데이트\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch%100==0:\n",
        "    print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "        epoch,nb_epochs,cost.item()\n",
        "    ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HU7ScpidQXN-",
        "outputId": "00ad2e98-bbc5-4eed-8774-5e6ea03de8a5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/2000 Cost: 18.562185\n",
            "Epoch  100/2000 Cost: 0.128051\n",
            "Epoch  200/2000 Cost: 0.079128\n",
            "Epoch  300/2000 Cost: 0.048896\n",
            "Epoch  400/2000 Cost: 0.030215\n",
            "Epoch  500/2000 Cost: 0.018671\n",
            "Epoch  600/2000 Cost: 0.011538\n",
            "Epoch  700/2000 Cost: 0.007129\n",
            "Epoch  800/2000 Cost: 0.004406\n",
            "Epoch  900/2000 Cost: 0.002722\n",
            "Epoch 1000/2000 Cost: 0.001682\n",
            "Epoch 1100/2000 Cost: 0.001040\n",
            "Epoch 1200/2000 Cost: 0.000642\n",
            "Epoch 1300/2000 Cost: 0.000397\n",
            "Epoch 1400/2000 Cost: 0.000245\n",
            "Epoch 1500/2000 Cost: 0.000152\n",
            "Epoch 1600/2000 Cost: 0.000094\n",
            "Epoch 1700/2000 Cost: 0.000058\n",
            "Epoch 1800/2000 Cost: 0.000036\n",
            "Epoch 1900/2000 Cost: 0.000022\n",
            "Epoch 2000/2000 Cost: 0.000014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 임의의 입력 4를 선언\n",
        "new_var=torch.FloatTensor([[4.0]])\n",
        "\n",
        "# 입력한 값 4에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
        "pred_y=model(new_var) # forward 연산**?\n",
        "# y=2x -> 입력=4라면, y=8에 가까운 값이 나와야 제대로 학습된 것.\n",
        "\n",
        "print(\"훈련 후 입력이 4일 때의 예측값: \", pred_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9g-m6Eu8REfn",
        "outputId": "a89197e5-2391-451f-c672-5429606609c3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 후 입력이 4일 때의 예측값:  tensor([[7.9926]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 후의 w와 b의 값 출력\n",
        "print(list(model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VXP2RBtSJAJ",
        "outputId": "2ac8bff1-5a92-4461-de7b-b2fb304271dc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[1.9957]], requires_grad=True), Parameter containing:\n",
            "tensor([0.0097], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   H(x) 식에 입력 x로부터 예측된 y를 얻는 것을 forward 연산이라고 한다.\n",
        "*   학습 전, prediction=model(x_train)은 x_train으로부터 예측값을 리턴하므로 forward연산\n",
        "*   학습 후, pred_y=model(new_var)는 임의의 값 new_var로부터 예측값을 리턴하므로 forward연산\n",
        "*   학습 과정에서 비용함수를 미분하여 기울기를 구하는 것 -> backward 연산\n",
        "*   cost.backward()는 비용 함수로부터 기울기를 구하라는 의미 -> backward 연산\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Nv_tGN4JSqjH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "N4-PfuQbSiXJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}