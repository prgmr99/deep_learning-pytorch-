{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LR_nn_Module.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPSJgUhG/RHZVvvXwMbED1v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prgmr99/deep_learning-pytorch-/blob/main/LR_nn_Module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **nn.Module로 구현하는 선형 회귀**\n",
        "\n",
        "이전까지는 선형 회귀를 좀 더 직접적으로 이해하기 위해 가설, 비용 함수를 직접 정의해서 선형 회귀 모델을 구현했다.\n",
        "\n",
        "이번에는 파이토치에서 이미 구현되어져 제공되고 있는 함수들을 불러오는 것으로 더 쉽게 선형 회귀 모델을 구현해보겠다.\n"
      ],
      "metadata": {
        "id": "7prsM9CpKeDs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_9QICmmeKBAa"
      },
      "outputs": [],
      "source": [
        "# 파이토치에서는 선형 회귀 모델이 nn.Linear()라는 함수로,\n",
        "# 평균 제곱오차가 nn.function.mse_loss()라는 함수로 구현되어져 있다.\n",
        "\n",
        "# 사용 예제\n",
        "import torch.nn as nn\n",
        "#model=nn.Linear(input_dim, output_dim) # 에러 떠서 주석처리\n",
        "\n",
        "import torch.nn.functional as F\n",
        "#cost=F.mse_loss(prediction, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **단순 선형 회귀 구현하기**"
      ],
      "metadata": {
        "id": "m2tlfnDqMAVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 도구 임포트\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jB31Sn04LgIt",
        "outputId": "e9f7d8b3-4e47-4407-e716-d40d3ded7ae2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fecfb0ffdd0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 선언(y=2*x를 가정한 상태에서 데이터 만듬)\n",
        "# w=2, b=0임을 알고 있기 때문에 w,b 값을 제대로 찾아내도록 하는 것이 목표.\n",
        "x_train=torch.FloatTensor(([1],[2],[3]))\n",
        "y_train=torch.FloatTensor(([2],[4],[6]))"
      ],
      "metadata": {
        "id": "52p_VOVxMS-L"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 선형 회귀 모델 구현\n",
        "# nn.Linear()는 입력의 차원, 출력의 차원을 인수로 받는다.\n",
        "\n",
        "# 모델을 선언/초기화. 단순 선형 회귀이므로 input_dim=1, output_dim=1\n",
        "model=nn.Linear(1,1)\n",
        "\n",
        "# 입력 차원과 출력 차원 모두 1을 인수로 사용.\n",
        "# model에는 가중치 w와 편향 b가 저장되어져 있다.\n",
        "# 이 값들은 model.parameters()라는 함수를 사용해 불러올 수 있다.\n",
        "print(list(model.parameters()))\n",
        "\n",
        "# 두 값 모두 현재는 랜덤 초기화가 되어져 있다. \n",
        "# 두 값 모두 학습의 대상이므로 requires_grad=True가 되어져 있다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAUqf6jnM0o7",
        "outputId": "1dd2c000-2e54-4cff-e640-8d30aa35d4e5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[0.5153]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.4414], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 옵티마이저 정의\n",
        "# model.parameters()를 사용하여 w와 b를 전달\n",
        "\n",
        "# optimizer 설정. 경사 하강법 SGD 사용, lr=0.01\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=0.01)"
      ],
      "metadata": {
        "id": "w52773r1OsKx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epochs=2000\n",
        "for epoch in range(nb_epochs+1):\n",
        "\n",
        "  # H(x) 계산\n",
        "  prediction=model(x_train)\n",
        "\n",
        "  # cost 계산\n",
        "  cost=F.mse_loss(prediction,y_train) # 파이토치에서 제공하는 평균 제곱 오차 함수\n",
        "\n",
        "  # cost로 H(x) 개선하는 부분\n",
        "  # gradient를 0으로 초기화\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # 비용 함수를 미분하여 gradient 계산\n",
        "  cost.backward()\n",
        "\n",
        "  # W와 b를 업데이트\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch%100==0:\n",
        "    print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "        epoch,nb_epochs,cost.item()\n",
        "    ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HU7ScpidQXN-",
        "outputId": "cc7bad34-3e34-4e22-a9fe-6e089cfd8103"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/2000 Cost: 13.103541\n",
            "Epoch  100/2000 Cost: 0.002791\n",
            "Epoch  200/2000 Cost: 0.001724\n",
            "Epoch  300/2000 Cost: 0.001066\n",
            "Epoch  400/2000 Cost: 0.000658\n",
            "Epoch  500/2000 Cost: 0.000407\n",
            "Epoch  600/2000 Cost: 0.000251\n",
            "Epoch  700/2000 Cost: 0.000155\n",
            "Epoch  800/2000 Cost: 0.000096\n",
            "Epoch  900/2000 Cost: 0.000059\n",
            "Epoch 1000/2000 Cost: 0.000037\n",
            "Epoch 1100/2000 Cost: 0.000023\n",
            "Epoch 1200/2000 Cost: 0.000014\n",
            "Epoch 1300/2000 Cost: 0.000009\n",
            "Epoch 1400/2000 Cost: 0.000005\n",
            "Epoch 1500/2000 Cost: 0.000003\n",
            "Epoch 1600/2000 Cost: 0.000002\n",
            "Epoch 1700/2000 Cost: 0.000001\n",
            "Epoch 1800/2000 Cost: 0.000001\n",
            "Epoch 1900/2000 Cost: 0.000000\n",
            "Epoch 2000/2000 Cost: 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 임의의 입력 4를 선언\n",
        "new_var=torch.FloatTensor([[4.0]])\n",
        "\n",
        "# 입력한 값 4에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
        "pred_y=model(new_var) # forward 연산**? -> 예측을 하기 위해 하는 연산\n",
        "# y=2x -> 입력=4라면, y=8에 가까운 값이 나와야 제대로 학습된 것.\n",
        "# w=2, b=0에 가까운 값이 나와야 한다.\n",
        "\n",
        "print(\"훈련 후 입력이 4일 때의 예측값: \", pred_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9g-m6Eu8REfn",
        "outputId": "57fa1256-9e22-4077-b712-379093841603"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 후 입력이 4일 때의 예측값:  tensor([[7.9989]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 후의 w와 b의 값 출력\n",
        "print(list(model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VXP2RBtSJAJ",
        "outputId": "d92e0a13-21c8-40ff-b50f-c00692c14d74"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[1.9994]], requires_grad=True), Parameter containing:\n",
            "tensor([0.0014], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   H(x) 식에 입력 x로부터 예측된 y를 얻는 것을 forward 연산이라고 한다.\n",
        "*   학습 전, prediction=model(x_train)은 x_train으로부터 예측값을 리턴하므로 forward연산\n",
        "*   학습 후, pred_y=model(new_var)는 임의의 값 new_var로부터 예측값을 리턴하므로 forward연산\n",
        "*   학습 과정에서 비용함수를 미분하여 기울기를 구하는 것 -> backward 연산\n",
        "*   cost.backward()는 비용 함수로부터 기울기를 구하라는 의미 -> backward 연산\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Nv_tGN4JSqjH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **다중 선형 회귀 구현하기**"
      ],
      "metadata": {
        "id": "TPmKzZEmUSA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# nn.Linear()와 nn.functional.mse_loss()로 다중 선형 회귀를 구현해보자.\n",
        "# 사실 코드 자체는 달라지는 건 거의 없다. nn.Linear()의 인자값과 학습률만 조절해주었다.\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "id": "N4-PfuQbSiXJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10dacd83-4572-4810-9db9-7efe8b85dfb6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fecfb0ffdd0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 선언\n",
        "# 3개의 x로부터 하나의 y를 예측하는 문제\n",
        "# H(x)=w1x1+w2x2+w3x3+b\n",
        "\n",
        "x_train=torch.FloatTensor([[73,80,75],\n",
        "                           [93,88,93],\n",
        "                           [89,91,90],\n",
        "                           [96,98,100],\n",
        "                           [73,66,70]])\n",
        "y_train=torch.FloatTensor([[152],[185],[180],[196],[142]])"
      ],
      "metadata": {
        "id": "BDKCL68yWA0x"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 선형 회귀 모델 구현. nn.Linear()은 입력의 차원, 출력의 차원을 인수로 받는다.\n",
        "# 모델을 선언 및 초기화. 다중 선형 회귀이므로 input_dim=3, ouput_dim=1\n",
        "model=nn.Linear(3,1)\n",
        "\n",
        "# torch.nn.Linear 인자로 3,1을 사용했다. 3개의 입력 x에 대해서 하나의 출력 y를 가지므로, 입력 차원은 3, 출력 차원은 1을 인수로 사용했다.\n",
        "# model에는 3개의 가중치 w와 편향 b가 저장되어있다. \n",
        "# 이 값은 역시 model.parameters()라는 함수로 사용하여 불러올 수 있다.\n",
        "print(list(model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ianydsxaWoSr",
        "outputId": "765baa22-7f8c-44ce-a090-92138ac747db"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[ 0.2975, -0.2548, -0.1119]], requires_grad=True), Parameter containing:\n",
            "tensor([0.2710], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 첫 번째 출력되는 것이 3개의 w, 두 번째 출력되는 것이 b에 해당. 두 값 모두 현재는 랜덤 초기화 되어있다.\n",
        "# 두 출력 결과 모두 학습의 대상이기 때문에 requires_grad=True\n",
        "\n",
        "# 옵티마이저 정의\n",
        "# model.parameters()를 사용하여 3개의 w와 b를 전달한다.\n",
        "# 학습률은 0.00001 = 1e-5 로 정한다. 0.01로 하면 기울기가 발산하기 때문이다. 궁금하면 시도 고고\n",
        "\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=1e-5)"
      ],
      "metadata": {
        "id": "rreuL8MRXnJL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epochs=2000\n",
        "for epoch in range(nb_epochs+1):\n",
        "\n",
        "  # H(x) 계산\n",
        "  prediction=model(x_train)\n",
        "  # model(x_train) = model.forward(x_train)\n",
        "\n",
        "  # cost 계산\n",
        "  cost=F.mse_loss(prediction, y_train) # 파이토치에서 제공하는 평귭 제곱 오차 함수\n",
        "\n",
        "  # cost로 H(x) 개선\n",
        "  # gradient를 0으로 초기화\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # 비용 함수를 미분하여 gradient 곗간\n",
        "  cost.backward()\n",
        "\n",
        "  # w와 b를 업데이트\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch%100==0:\n",
        "    print('Epoch {:4d}/{} Cost: {:.6f}'.format(epoch,nb_epochs,cost.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDZ1XHNEZtg4",
        "outputId": "1ae2af1b-4c23-470a-d03b-28c6b912afcf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/2000 Cost: 31667.597656\n",
            "Epoch  100/2000 Cost: 0.225988\n",
            "Epoch  200/2000 Cost: 0.223910\n",
            "Epoch  300/2000 Cost: 0.221930\n",
            "Epoch  400/2000 Cost: 0.220059\n",
            "Epoch  500/2000 Cost: 0.218270\n",
            "Epoch  600/2000 Cost: 0.216571\n",
            "Epoch  700/2000 Cost: 0.214955\n",
            "Epoch  800/2000 Cost: 0.213413\n",
            "Epoch  900/2000 Cost: 0.211949\n",
            "Epoch 1000/2000 Cost: 0.210558\n",
            "Epoch 1100/2000 Cost: 0.209237\n",
            "Epoch 1200/2000 Cost: 0.207971\n",
            "Epoch 1300/2000 Cost: 0.206764\n",
            "Epoch 1400/2000 Cost: 0.205616\n",
            "Epoch 1500/2000 Cost: 0.204527\n",
            "Epoch 1600/2000 Cost: 0.203479\n",
            "Epoch 1700/2000 Cost: 0.202487\n",
            "Epoch 1800/2000 Cost: 0.201542\n",
            "Epoch 1900/2000 Cost: 0.200638\n",
            "Epoch 2000/2000 Cost: 0.199769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cost의 값이 매우 작다. 3개의 w와 b의 값도 최적화가 되었는지 확인해보자.\n",
        "# x에 임의의 입력 [73,80,75]를 넣어 모델이 예측하는 y의 값을 확인해보자.\n",
        "\n",
        "new_var=torch.FloatTensor([[73,80,75]])\n",
        "\n",
        "# 입력한 값에 대해서 예측값 y를 리턴받아 pred_y에 저장\n",
        "pred_y=model(new_var)\n",
        "print(\"훈련 후 입력이 73,80,75일 때의 예측값: \", pred_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2kfq4_gbYcS",
        "outputId": "1220635e-59b6-4013-9d56-e58ac9ed9dc6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 후 입력이 73,80,75일 때의 예측값:  tensor([[151.2305]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olceSv-GcPCz",
        "outputId": "fc26a6b2-d23a-4202-d6c6-f9b4e51e40bd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[0.9778, 0.4539, 0.5768]], requires_grad=True), Parameter containing:\n",
            "tensor([0.2802], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UQ24GKYAclYm"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}