{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LR_nn_Module.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPSJgUhG/RHZVvvXwMbED1v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prgmr99/deep_learning-pytorch-/blob/main/LR_nn_Module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **nn.Module로 구현하는 선형 회귀**\n",
        "\n",
        "이전까지는 선형 회귀를 좀 더 직접적으로 이해하기 위해 가설, 비용 함수를 직접 정의해서 선형 회귀 모델을 구현했다.\n",
        "\n",
        "이번에는 파이토치에서 이미 구현되어져 제공되고 있는 함수들을 불러오는 것으로 더 쉽게 선형 회귀 모델을 구현해보겠다.\n"
      ],
      "metadata": {
        "id": "7prsM9CpKeDs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9QICmmeKBAa"
      },
      "outputs": [],
      "source": [
        "# 파이토치에서는 선형 회귀 모델이 nn.Linear()라는 함수로,\n",
        "# 평균 제곱오차가 nn.function.mse_loss()라는 함수로 구현되어져 있다.\n",
        "\n",
        "# 사용 예제\n",
        "import torch.nn as nn\n",
        "#model=nn.Linear(input_dim, output_dim) # 에러 떠서 주석처리\n",
        "\n",
        "import torch.nn.functional as F\n",
        "#cost=F.mse_loss(prediction, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **단순 선형 회귀 구현하기**"
      ],
      "metadata": {
        "id": "m2tlfnDqMAVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 도구 임포트\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jB31Sn04LgIt",
        "outputId": "e267550e-89f3-4f46-964d-ce2d47a69fc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f8e40474dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 선언(y=2*x를 가정한 상태에서 데이터 만듬)\n",
        "# w=2, b=0임을 알고 있기 때문에 w,b 값을 제대로 찾아내도록 하는 것이 목표.\n",
        "x_train=torch.FloatTensor(([1],[2],[3]))\n",
        "y_train=torch.FloatTensor(([2],[4],[6]))"
      ],
      "metadata": {
        "id": "52p_VOVxMS-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 선형 회귀 모델 구현\n",
        "# nn.Linear()는 입력의 차원, 출력의 차원을 인수로 받는다.\n",
        "\n",
        "# 모델을 선언/초기화. 단순 선형 회귀이므로 input_dim=1, output_dim=1\n",
        "model=nn.Linear(1,1)\n",
        "\n",
        "# 입력 차원과 출력 차원 모두 1을 인수로 사용.\n",
        "# model에는 가중치 w와 편향 b가 저장되어져 있다.\n",
        "# 이 값들은 model.parameters()라는 함수를 사용해 불러올 수 있다.\n",
        "print(list(model.parameters()))\n",
        "\n",
        "# 두 값 모두 현재는 랜덤 초기화가 되어져 있다. \n",
        "# 두 값 모두 학습의 대상이므로 requires_grad=True가 되어져 있다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAUqf6jnM0o7",
        "outputId": "7f5800f4-8293-4cc5-864b-4b1b4bd5b798"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[0.5153]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.4414], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 옵티마이저 정의\n",
        "# model.parameters()를 사용하여 w와 b를 전달\n",
        "\n",
        "# optimizer 설정. 경사 하강법 SGD 사용, lr=0.01\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=0.01)"
      ],
      "metadata": {
        "id": "w52773r1OsKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epochs=2000\n",
        "for epoch in range(nb_epochs+1):\n",
        "\n",
        "  # H(x) 계산\n",
        "  prediction=model(x_train)\n",
        "\n",
        "  # cost 계산\n",
        "  cost=F.mse_loss(prediction,y_train) # 파이토치에서 제공하는 평균 제곱 오차 함수\n",
        "\n",
        "  # cost로 H(x) 개선하는 부분\n",
        "  # gradient를 0으로 초기화\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # 비용 함수를 미분하여 gradient 계산\n",
        "  cost.backward()\n",
        "\n",
        "  # W와 b를 업데이트\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch%100==0:\n",
        "    print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "        epoch,nb_epochs,cost.item()\n",
        "    ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HU7ScpidQXN-",
        "outputId": "09e23169-ef38-4813-d438-d79e8f9c9d2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/2000 Cost: 13.103541\n",
            "Epoch  100/2000 Cost: 0.002791\n",
            "Epoch  200/2000 Cost: 0.001724\n",
            "Epoch  300/2000 Cost: 0.001066\n",
            "Epoch  400/2000 Cost: 0.000658\n",
            "Epoch  500/2000 Cost: 0.000407\n",
            "Epoch  600/2000 Cost: 0.000251\n",
            "Epoch  700/2000 Cost: 0.000155\n",
            "Epoch  800/2000 Cost: 0.000096\n",
            "Epoch  900/2000 Cost: 0.000059\n",
            "Epoch 1000/2000 Cost: 0.000037\n",
            "Epoch 1100/2000 Cost: 0.000023\n",
            "Epoch 1200/2000 Cost: 0.000014\n",
            "Epoch 1300/2000 Cost: 0.000009\n",
            "Epoch 1400/2000 Cost: 0.000005\n",
            "Epoch 1500/2000 Cost: 0.000003\n",
            "Epoch 1600/2000 Cost: 0.000002\n",
            "Epoch 1700/2000 Cost: 0.000001\n",
            "Epoch 1800/2000 Cost: 0.000001\n",
            "Epoch 1900/2000 Cost: 0.000000\n",
            "Epoch 2000/2000 Cost: 0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 임의의 입력 4를 선언\n",
        "new_var=torch.FloatTensor([[4.0]])\n",
        "\n",
        "# 입력한 값 4에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
        "pred_y=model(new_var) # forward 연산**? -> 예측을 하기 위해 하는 연산\n",
        "# y=2x -> 입력=4라면, y=8에 가까운 값이 나와야 제대로 학습된 것.\n",
        "# w=2, b=0에 가까운 값이 나와야 한다.\n",
        "\n",
        "print(\"훈련 후 입력이 4일 때의 예측값: \", pred_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "9g-m6Eu8REfn",
        "outputId": "de15423e-b563-4512-f26f-df4c4a5bc3a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-748e82be9203>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 입력한 값 4에 대해서 예측값 y를 리턴받아서 pred_y에 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpred_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_var\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# forward 연산**? -> 예측을 하기 위해 하는 연산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# y=2x -> 입력=4라면, y=8에 가까운 값이 나와야 제대로 학습된 것.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# w=2, b=0에 가까운 값이 나와야 한다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x1 and 3x1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 후의 w와 b의 값 출력\n",
        "print(list(model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VXP2RBtSJAJ",
        "outputId": "52a5f223-cfc2-4011-a898-d442f5da5657"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[1.9994]], requires_grad=True), Parameter containing:\n",
            "tensor([0.0014], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   H(x) 식에 입력 x로부터 예측된 y를 얻는 것을 forward 연산이라고 한다.\n",
        "*   학습 전, prediction=model(x_train)은 x_train으로부터 예측값을 리턴하므로 forward연산\n",
        "*   학습 후, pred_y=model(new_var)는 임의의 값 new_var로부터 예측값을 리턴하므로 forward연산\n",
        "*   학습 과정에서 비용함수를 미분하여 기울기를 구하는 것 -> backward 연산\n",
        "*   cost.backward()는 비용 함수로부터 기울기를 구하라는 의미 -> backward 연산\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Nv_tGN4JSqjH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **다중 선형 회귀 구현하기**"
      ],
      "metadata": {
        "id": "TPmKzZEmUSA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# nn.Linear()와 nn.functional.mse_loss()로 다중 선형 회귀를 구현해보자.\n",
        "# 사실 코드 자체는 달라지는 건 거의 없다. nn.Linear()의 인자값과 학습률만 조절해주었다.\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "metadata": {
        "id": "N4-PfuQbSiXJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "900ffed0-ff75-4f9d-a332-0ffd252d9213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f8e40474dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 선언\n",
        "# 3개의 x로부터 하나의 y를 예측하는 문제\n",
        "# H(x)=w1x1+w2x2+w3x3+b\n",
        "\n",
        "x_train=torch.FloatTensor([[73,80,75],\n",
        "                           [93,88,93],\n",
        "                           [89,91,90],\n",
        "                           [96,98,100],\n",
        "                           [73,66,70]])\n",
        "y_train=torch.FloatTensor([[152],[185],[180],[196],[142]])"
      ],
      "metadata": {
        "id": "BDKCL68yWA0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 선형 회귀 모델 구현. nn.Linear()은 입력의 차원, 출력의 차원을 인수로 받는다.\n",
        "# 모델을 선언 및 초기화. 다중 선형 회귀이므로 input_dim=3, ouput_dim=1\n",
        "model=nn.Linear(3,1)\n",
        "\n",
        "# torch.nn.Linear 인자로 3,1을 사용했다. 3개의 입력 x에 대해서 하나의 출력 y를 가지므로, 입력 차원은 3, 출력 차원은 1을 인수로 사용했다.\n",
        "# model에는 3개의 가중치 w와 편향 b가 저장되어있다. \n",
        "# 이 값은 역시 model.parameters()라는 함수로 사용하여 불러올 수 있다.\n",
        "print(list(model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ianydsxaWoSr",
        "outputId": "c807bfce-9c11-4863-8817-abd26ea8b429"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[-0.5435,  0.3462, -0.1188]], requires_grad=True), Parameter containing:\n",
            "tensor([0.2937], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 첫 번째 출력되는 것이 3개의 w, 두 번째 출력되는 것이 b에 해당. 두 값 모두 현재는 랜덤 초기화 되어있다.\n",
        "# 두 출력 결과 모두 학습의 대상이기 때문에 requires_grad=True\n",
        "\n",
        "# 옵티마이저 정의\n",
        "# model.parameters()를 사용하여 3개의 w와 b를 전달한다.\n",
        "# 학습률은 0.00001 = 1e-5 로 정한다. 0.01로 하면 기울기가 발산하기 때문이다. 궁금하면 시도 고고\n",
        "\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=1e-5)"
      ],
      "metadata": {
        "id": "rreuL8MRXnJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epochs=2000\n",
        "for epoch in range(nb_epochs+1):\n",
        "\n",
        "  # H(x) 계산\n",
        "  prediction=model(x_train)\n",
        "  # model(x_train) = model.forward(x_train)\n",
        "\n",
        "  # cost 계산\n",
        "  cost=F.mse_loss(prediction, y_train) # 파이토치에서 제공하는 평귭 제곱 오차 함수\n",
        "\n",
        "  # cost로 H(x) 개선\n",
        "  # gradient를 0으로 초기화\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # 비용 함수를 미분하여 gradient 곗간\n",
        "  cost.backward()\n",
        "\n",
        "  # w와 b를 업데이트\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch%100==0:\n",
        "    print('Epoch {:4d}/{} Cost: {:.6f}'.format(epoch,nb_epochs,cost.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDZ1XHNEZtg4",
        "outputId": "672a47a1-e982-4adb-8c46-56e41471994d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/2000 Cost: 39633.414062\n",
            "Epoch  100/2000 Cost: 11.480746\n",
            "Epoch  200/2000 Cost: 10.894592\n",
            "Epoch  300/2000 Cost: 10.339335\n",
            "Epoch  400/2000 Cost: 9.813351\n",
            "Epoch  500/2000 Cost: 9.315010\n",
            "Epoch  600/2000 Cost: 8.842962\n",
            "Epoch  700/2000 Cost: 8.395753\n",
            "Epoch  800/2000 Cost: 7.972028\n",
            "Epoch  900/2000 Cost: 7.570637\n",
            "Epoch 1000/2000 Cost: 7.190376\n",
            "Epoch 1100/2000 Cost: 6.830142\n",
            "Epoch 1200/2000 Cost: 6.488811\n",
            "Epoch 1300/2000 Cost: 6.165472\n",
            "Epoch 1400/2000 Cost: 5.859105\n",
            "Epoch 1500/2000 Cost: 5.568909\n",
            "Epoch 1600/2000 Cost: 5.293931\n",
            "Epoch 1700/2000 Cost: 5.033408\n",
            "Epoch 1800/2000 Cost: 4.786575\n",
            "Epoch 1900/2000 Cost: 4.552718\n",
            "Epoch 2000/2000 Cost: 4.331151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cost의 값이 매우 작다. 3개의 w와 b의 값도 최적화가 되었는지 확인해보자.\n",
        "# x에 임의의 입력 [73,80,75]를 넣어 모델이 예측하는 y의 값을 확인해보자.\n",
        "\n",
        "new_var=torch.FloatTensor([[73,80,75]])\n",
        "\n",
        "# 입력한 값에 대해서 예측값 y를 리턴받아 pred_y에 저장\n",
        "pred_y=model(new_var)\n",
        "print(\"훈련 후 입력이 73,80,75일 때의 예측값: \", pred_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2kfq4_gbYcS",
        "outputId": "d7515280-a058-44c7-d6f0-add4bdba6580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 후 입력이 73,80,75일 때의 예측값:  tensor([[153.9886]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olceSv-GcPCz",
        "outputId": "2a2e8b71-4200-4808-94a2-bfd0ba13ab98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[0.4789, 0.8222, 0.7059]], requires_grad=True), Parameter containing:\n",
            "tensor([0.3070], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UQ24GKYAclYm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}