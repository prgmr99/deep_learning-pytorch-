{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LR_multivariable.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMTmCFtbSMCzsVHIx+Bjg3v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prgmr99/deep_learning-pytorch-/blob/main/LR_multivariable.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **다중 선형 회귀(Multivariable Linear Regression)**"
      ],
      "metadata": {
        "id": "DpvCqHHwUH86"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDd_GmubSDdi",
        "outputId": "d66c8d40-a204-47a2-b700-0175924ec79f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fea96037db0>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# 필요한 도구들을 임포트하고 랜덤 시드 고정\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 데이터 선언\n",
        "# H(x) = w1*x1 + w2*x2 + w3*x3 + b\n",
        "# 단순 선형 회귀와 다르게 x의 개수가 3개가 주어진다.\n",
        "x1_train=torch.FloatTensor([[73],[89],[96],[73]])\n",
        "x2_train=torch.FloatTensor([[80],[91],[98],[66]])\n",
        "x3_train=torch.FloatTensor([[75],[90],[100],[70]])\n",
        "y_train=torch.FloatTensor([[152],[185],[196],[142]])"
      ],
      "metadata": {
        "id": "Shfs4urzVXNh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 가중치 w와 편향 b를 선언한다. 가중치 w도 3개 선언해주어야 한다.\n",
        "w1=torch.zeros(1,requires_grad=True)\n",
        "w2=torch.zeros(1,requires_grad=True)\n",
        "w3=torch.zeros(1,requires_grad=True)\n",
        "b=torch.zeros(1,requires_grad=True)"
      ],
      "metadata": {
        "id": "QxpSDA20WILx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 가설, 비용 함수, 옵티마이저를 선언한 후에 경사 하강법을 1,000회 반복한다.\n",
        "optimizer=optim.SGD([w1,w2,w3,b],lr=1e-5)\n",
        "\n",
        "nb_epochs=1000\n",
        "for epoch in range(nb_epochs+1):\n",
        "  # H(x) 계산\n",
        "  hypothesis=x1_train*w1+x2_train*w2+x3_train*w3+b\n",
        "  # cost 계산\n",
        "  cost=torch.mean((hypothesis-y_train)**2)\n",
        "  # cost로 H(x) 개선\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  # 100번마다 로그 출력\n",
        "  if epoch % 100 == 0:\n",
        "    print('Epoch {:4d}/{} w1: {:.3f} w2: {:.3f} w3: {:.3f} b: {:.3f} Cost: {:.6f}'.format(\n",
        "        epoch,nb_epochs,w1.item(),w2.item(),w3.item(),b.item(),cost.item()\n",
        "    ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lp2aWewbWWmI",
        "outputId": "9610dfc9-257a-43cf-b850-1b9e27f66758"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch    0/1000 w1: 0.447 w2: 0.453 w3: 0.454 b: 0.005 Cost: 9582.213867\n",
            "Epoch  100/1000 w1: 0.673 w2: 0.673 w3: 0.676 b: 0.008 Cost: 4.467774\n",
            "Epoch  200/1000 w1: 0.678 w2: 0.669 w3: 0.675 b: 0.008 Cost: 4.425721\n",
            "Epoch  300/1000 w1: 0.683 w2: 0.666 w3: 0.674 b: 0.008 Cost: 4.385494\n",
            "Epoch  400/1000 w1: 0.688 w2: 0.662 w3: 0.673 b: 0.008 Cost: 4.347049\n",
            "Epoch  500/1000 w1: 0.692 w2: 0.659 w3: 0.672 b: 0.008 Cost: 4.310228\n",
            "Epoch  600/1000 w1: 0.697 w2: 0.655 w3: 0.670 b: 0.008 Cost: 4.275028\n",
            "Epoch  700/1000 w1: 0.702 w2: 0.652 w3: 0.669 b: 0.009 Cost: 4.241343\n",
            "Epoch  800/1000 w1: 0.706 w2: 0.649 w3: 0.668 b: 0.009 Cost: 4.209073\n",
            "Epoch  900/1000 w1: 0.711 w2: 0.645 w3: 0.667 b: 0.009 Cost: 4.178172\n",
            "Epoch 1000/1000 w1: 0.715 w2: 0.642 w3: 0.666 b: 0.009 Cost: 4.148612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AWv-TMApZ9iZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}